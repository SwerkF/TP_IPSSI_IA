import streamlit as st
from PIL import Image
import os
import tensorflow as tf  # Pour charger les mod√®les TensorFlow
from tensorflow.keras import models  # Pour charger les mod√®les .keras
import pickle  # Pour charger les mod√®les scikit-learn sauvegard√©s en .pkl
import joblib  # Pour charger les mod√®les scikit-learn en utilisant joblib
import torch  # Pour charger les mod√®les PyTorch
import torch.nn as nn  # Pour d√©finir et utiliser le mod√®le CNN PyTorch
import numpy as np  # Pour travailler avec des matrices d'image
import pandas as pd
import matplotlib.pyplot as plt

# Charger le mod√®le s√©lectionn√©
def load_selected_model(model_path):
    try:
        if model_path.endswith('.keras'):
            # Load a TensorFlow model
            model = models.load_model(model_path)
            return model, "tensorflow"
        elif model_path.endswith('.pkl'):
            # Load a scikit-learn model (pkl)
            with open(model_path, 'rb') as file:
                try:
                    model = pickle.load(file)
                except Exception:
                    model = joblib.load(model_path)  # Load with joblib if pickle fails
            return model, "mlp"
        elif model_path.endswith('.pth'):
            # Load a PyTorch model
            model = CNNModel()
            model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))  # Load to CPU
            model.eval()  # Set the model to evaluation mode
            return model, "pytorch"
        else:
            st.error("Unsupported model format.")
            st.stop()
    except Exception as e:
        st.error(f"Error loading model: {e}")
        st.stop()

# D√©finir le mod√®le CNN pour PyTorch
class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=3),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )
        
        # Calculer la taille d'entr√©e pour la couche dense
        with torch.no_grad():
            dummy_input = torch.zeros(1, 3, 224, 224)
            output_size = self.features(dummy_input).view(-1).shape[0]
        
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(output_size, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# Configuration de la page Streamlit (unique, doit √™tre la premi√®re commande)
st.set_page_config(
    page_title="D√©tection du Cancer de la Peau",
    page_icon="üè•",
    layout="wide"
)

# Barre lat√©rale pour la navigation entre les pages
st.sidebar.title("Navigation")
page = st.sidebar.selectbox("Choisissez une page", ["Accueil", "Analyse Exploratoire des Donn√©es", "Faire une Pr√©diction par Image", "Faire une Pr√©diction par Profil" ,"Benchmark des Mod√®les"])

# Liste des mod√®les disponibles pour la pr√©diction (pour la page "Faire une Pr√©diction")
model_dir = './saved_models'
models_available = [f for f in os.listdir(model_dir) if f.endswith(('.keras', '.pkl', '.pth')) and not f.startswith(('encoders', 'mlp_model', 'scaler'))]

# Page d'accueil
if page == "Accueil":
    st.title("üè• Pr√©dire un cancer de la peau avec une image")

    # Introduction du projet
    st.markdown("""
    ### Introduction du projet üè•

    Ce projet a √©t√© d√©velopp√© dans le cadre du **cours d'analyse de donn√©es pour une IA**, afin de mettre en pratique les concepts de **deep learning** et de **machine learning**. L'objectif est de cr√©er un **outil accessible** qui permet de d√©tecter les signes pr√©coces de **cancer de la peau** √† partir d'une simple image de la l√©sion cutan√©e. En utilisant des mod√®les avanc√©s, nous souhaitons non seulement aider √† la sensibilisation sur les risques potentiels des l√©sions cutan√©es, mais aussi acqu√©rir des comp√©tences en d√©veloppement de mod√®les IA appliqu√©s.

    ### Mod√®les Utilis√©s
    Pour ce projet, nous avons mis en place et test√© plusieurs mod√®les de r√©seaux de neurones avanc√©s, parmi lesquels :

    - **VGG16** : Mod√®le pr√©-entra√Æn√© pour la classification d'images.
    - **ResNet50** : R√©seau r√©sidu profond permettant de travailler sur des architectures complexes.
    - **EfficientNetB0** : Mod√®le moderne, √©quilibrant pr√©cision et efficacit√© des calculs.
    - **MLP (Perceptron multicouche)** : Pour servir de baseline et comparer avec des mod√®les plus avanc√©s.
    - **CNN PyTorch** et un **mod√®le TensorFlow personnalis√©** pour plus de flexibilit√©.

    ### Comment Utiliser l'Application
    Pour utiliser cette application, c'est simple :
    1. **Naviguez vers la page "Faire une Pr√©diction"** en utilisant la barre lat√©rale.
    2. **Choisissez un mod√®le** parmi ceux disponibles (par exemple, VGG16, ResNet50).
    3. **T√©l√©chargez une image** de la l√©sion cutan√©e que vous souhaitez analyser.
    4. Obtenez une pr√©diction indiquant si la l√©sion est probablement **b√©nigne** ou **maligne**.
    """)

# Page d'analyse exploratoire des donn√©es
elif page == "Analyse Exploratoire des Donn√©es":
    st.title("üìä Analyse et Visualisation avec un Arbre de D√©cision")

    st.markdown("""
        Ce projet d√©montre l'utilisation d'un mod√®le **Arbre de D√©cision** et **For√™t Al√©atoire** pour analyser un dataset li√© aux maladies de la peau. L'objectif est d'identifier les variables les plus importantes et de trouver des mod√®les efficaces pour pr√©dire si une personne a eu un cancer de la peau (`HadSkinCancer`).

        ## **1. Explication du Code**

        Le projet utilise Python avec des biblioth√®ques comme `scikit-learn` et `matplotlib`. Voici les √©tapes principales :

        ### **√âtapes dans le Code**

        1. **Chargement des donn√©es :**
        - Le dataset est charg√© √† partir d'un fichier Excel.
        - La colonne cible est `HadSkinCancer`, qui indique si une personne a eu un cancer de la peau.

        2. **Pr√©traitement des donn√©es :**
        - Les fonctions `preprocess_data` et `clean_data` sont utilis√©es pour nettoyer et encoder les variables cat√©goriques.

        3. **Matrice de corr√©lation :**
        - Une matrice de corr√©lation est calcul√©e pour visualiser les relations entre toutes les variables, y compris la cible (`HadSkinCancer`).

        4. **S√©paration des donn√©es :**
        - Les donn√©es sont divis√©es en un ensemble d'entra√Ænement (80%) et un ensemble de test (20%).

        5. **Entra√Ænement et √©valuation des mod√®les :**
        - **Arbre de D√©cision :** Une boucle teste des mod√®les d'Arbre de D√©cision avec des profondeurs variant de 1 √† 20.
            - Les m√©triques suivantes sont calcul√©es : pr√©cision (train et test), √©cart de pr√©cision (*Accuracy Gap*), taille de l'arbre.
        - **For√™t Al√©atoire :** Un mod√®le avec plusieurs arbres est entra√Æn√© pour comparer ses performances √† celles de l'Arbre de D√©cision.

        6. **Visualisations g√©n√©r√©es :**
        - **Matrice de corr√©lation** : Relations entre les variables.
        - **Meilleur arbre** : Visualisation de l'arbre pour la profondeur optimale.
        - **Importances des caract√©ristiques** : Variables ayant le plus d'influence dans les pr√©dictions (pour les deux mod√®les).
        - **Courbes ROC** : Capacit√© des mod√®les √† distinguer les classes.
        - **Analyse des pr√©cisions** : Comparaison des pr√©cisions d'entra√Ænement et de test pour l'Arbre de D√©cision.

        ## **2. Interpr√©tation des R√©sultats**

        ### **Graphique 1 : Train vs Test Accuracy and Accuracy Gap**
    """)
    image1 = Image.open("data/images/accuracy_gap_analysis.png")
    st.image(image1, caption="Image t√©l√©charg√©e √† analyser")
    st.markdown("""
        - **Observation** : 
            - La pr√©cision d'entra√Ænement augmente avec la profondeur, tandis que la pr√©cision de test se stabilise pour des profondeurs entre 5 et 10.
            - L'√©cart de pr√©cision (*Accuracy Gap*) reste faible pour des profondeurs mod√©r√©es mais augmente pour des arbres plus profonds.
        - **Interpr√©tation** :
            - Les arbres profonds tendent √† sur-apprendre (*overfitting*), ce qui r√©duit leur capacit√© √† g√©n√©raliser sur de nouvelles donn√©es.

        ### **Graphique 2 : Visualisation du Meilleur Arbre**
    """)
    image2 = Image.open("data/images/best_decision_tree_visualization.png")
    st.image(image2, caption="Image t√©l√©charg√©e √† analyser")
    st.markdown("""
        - **Observation** :
            - L‚Äôarbre montre que les premi√®res d√©cisions sont principalement bas√©es sur `AgeCategory`, suivi de `EthnicityCategory`.
            - Les n≈ìuds sup√©rieurs divisent les donn√©es en groupes significatifs, maximisant la s√©paration entre les classes.
            - **Interpr√©tation d√©taill√©e** :
            - **Crit√®res de d√©cision (n≈ìuds sup√©rieurs)** :
                - L'utilisation de `AgeCategory` en haut de l‚Äôarbre refl√®te son r√¥le dominant dans la pr√©diction. Par exemple :
                - Si une personne est dans une cat√©gorie d'√¢ge avanc√©, le mod√®le peut pr√©dire avec une grande probabilit√© la pr√©sence d'un risque accru.
                - `EthnicityCategory`, souvent utilis√© dans les premiers n≈ìuds, divise les individus en fonction de leur sensibilit√© aux dommages UV.
            - **D√©cisions fines (n≈ìuds inf√©rieurs)** :
                - Les caract√©ristiques comme `AlcoholDrinkers` ou `BMI`, bien que moins importantes globalement, sont utilis√©es pour affiner les pr√©dictions dans des sous-groupes sp√©cifiques.
            - **Feuilles de l'arbre** :
                - Les probabilit√©s pr√©sentes aux feuilles permettent d'identifier la classe pr√©dite (cancer de la peau ou non) ainsi que le degr√© de certitude de la pr√©diction.
            - **Explication contextuelle** :
            - Cet arbre de d√©cision met en lumi√®re les relations cl√©s dans les donn√©es et peut √™tre utilis√© pour :
                - Identifier rapidement les groupes √† haut risque.
                - √âlaborer des strat√©gies cibl√©es, comme des campagnes de d√©pistage adapt√©es aux profils les plus vuln√©rables.


            ### **Graphique 3 : Importances des Caract√©ristiques (Profondeur Optimale)**
    """)
    image3 = Image.open("data/images/feature_importances_best_depth.png")
    st.image(image3, caption="Image t√©l√©charg√©e √† analyser")
    st.markdown("""
        - **Observation** :
            - `AgeCategory` est la variable la plus influente, suivie de `EthnicityCategory`. Les autres caract√©ristiques, comme `BMI` et `AlcoholDrinkers`, ont un impact limit√©.
            - **Interpr√©tation d√©taill√©e** :
            - **AgeCategory (importance √©lev√©e)** :
                - L‚Äô√¢ge est un facteur critique dans les maladies de la peau, notamment le cancer de la peau, car :
                - L‚Äôexposition cumulative au soleil au fil des ans augmente les risques.
                - Les processus biologiques li√©s au vieillissement r√©duisent les capacit√©s de r√©paration de l‚ÄôADN apr√®s des dommages caus√©s par les UV.
                - Les groupes d'√¢ge plus avanc√©s sont plus fr√©quemment diagnostiqu√©s avec des cancers de la peau dans les √©tudes √©pid√©miologiques.
            - **EthnicityCategory (importance √©lev√©e)** :
                - L‚Äôethnicit√© joue un r√¥le cl√©, car :
                - Les personnes ayant une peau plus claire ont g√©n√©ralement une concentration plus faible de m√©lanine, ce qui les rend plus vuln√©rables aux dommages UV.
                - Les diff√©rences dans les comportements culturels, comme la protection solaire ou les habitudes d'exposition, peuvent √©galement influencer ce facteur.
            - **AlcoholDrinkers et BMI (importance mod√©r√©e)** :
                - Bien que ces variables aient une importance moindre, elles peuvent refl√©ter des comportements li√©s √† la sant√© globale :
                - Une consommation excessive d'alcool peut affaiblir le syst√®me immunitaire et r√©duire la capacit√© √† r√©parer les cellules endommag√©es.
                - L‚Äôindice de masse corporelle (BMI) est parfois li√© √† des comportements de sant√© globaux (par exemple, l'activit√© physique et l'exposition au soleil).
            - **Explication contextuelle** :
            - Ces r√©sultats confirment des tendances bien document√©es dans les recherches m√©dicales.

        ### **Graphique 4 : Importances des Caract√©ristiques (Profondeur = 9)**
    """)
    image4 = Image.open("data/images/feature_importances_depth_9.png")
    st.image(image4, caption="Image t√©l√©charg√©e √† analyser")
    st.markdown("""
        - **Observation** :
            - Les tendances sont similaires √† celles de la profondeur optimale.
        - **Interpr√©tation** :
            - Une profondeur de 9 est coh√©rente avec le meilleur mod√®le et offre un bon √©quilibre entre performance et simplicit√©.


        ### **Graphique 5 : Courbes ROC**
    """)
    image5 = Image.open("data/images/roc_curve.png")
    image5_1 = Image.open("data/images/rf_roc_curve.png")
    st.image(image5, caption="Image t√©l√©charg√©e √† analyser")
    st.image(image5_1, caption="Image t√©l√©charg√©e √† analyser")
    st.markdown("""
        - **Observation** :
            - L'AUC pour la For√™t Al√©atoire est l√©g√®rement meilleure que celle de l'Arbre de D√©cision.
        - **Interpr√©tation** :
            - La For√™t Al√©atoire offre une meilleure capacit√© de discrimination entre les classes.

        ### **Graphique 6 : Matrice de Corr√©lation**
    """)
    image6 = Image.open("data/images/correlation_matrix_with_target.png")
    st.image(image6, caption="Image t√©l√©charg√©e √† analyser")
    st.markdown("""
        - **Observation** :
            - `AgeCategory` et `EthnicityCategory` montrent des corr√©lations significatives avec la cible `HadSkinCancer`.
        - **Interpr√©tation** :
            - Ces relations confirment les r√©sultats des mod√®les, mettant en avant leur pertinence pour pr√©dire le cancer de la peau.

        ### **Tableau r√©capitulatif des r√©sultats**
    """)

    image7 = Image.open("data/images/decision_tree_summary_table.png")
    st.image(image7, caption="Image t√©l√©charg√©e √† analyser")
    st.markdown("""
        - **Observation** :
            - Une profondeur de 5 offre une pr√©cision optimale avec un √©cart de pr√©cision minimal.
        - **Interpr√©tation** :
            - Les profondeurs sup√©rieures √† 10 n'apportent pas de gains significatifs et augmentent le risque de sur-apprentissage.
    """)

    # Titre principal
    st.title("üìä Analyse de Mod√®les : KNN, K-Means et R√©gression Logistique")

    # Section 1 : Mod√®le KNN
    st.header("Mod√®le K-Nearest Neighbors (KNN)")

    # R√©sultats du mod√®le
    st.subheader("R√©sultats du Mod√®le KNN")
    st.image("data/images/results_knn.png", caption="R√©sultats du mod√®le KNN")

    # M√©thode du coude
    st.subheader("M√©thode du Coude")
    st.image("data/images/elbow_knn.png", caption="M√©thode du coude")
    st.markdown("""
    La m√©thode du coude a √©t√© utilis√©e pour choisir une valeur optimale pour k.  
    Le taux d'erreur diminue rapidement jusqu'√† une stabilisation autour de **k=10**, sugg√©rant un √©quilibre entre complexit√© et performance.  
    **Observation :**  
        - Une valeur de k=10 est recommand√©e pour obtenir un compromis entre un faible taux d'erreur et une complexit√© acceptable.
    """)

    # Matrice de confusion
    st.subheader("Matrice de Confusion")
    st.markdown("""
    |                | Pr√©dit : Non | Pr√©dit : Oui |
    |----------------|--------------|--------------|
    | **R√©el : Non** | 43,406 (TN)  | 155 (FP)     |
    | **R√©el : Oui** | 3,910 (FN)   | 55 (TP)      |
    """)
    st.markdown("""
    **Observations :**  
        - Classe 0 (Non) : Tr√®s efficace avec 43,406 pr√©dictions correctes et 155 erreurs.  
        - Classe 1 (Oui) : Faible performance avec seulement 55 cas correctement d√©tect√©s sur 3,965.
    """)

    # Rapport de classification
    st.subheader("Rapport de Classification")
    st.markdown("""
    | Classe | Pr√©cision | Rappel | F1-Score | Support |
    |--------|-----------|--------|----------|---------|
    | 0.0    | 0.92      | 1.00   | 0.96     | 43,561  |
    | 1.0    | 0.26      | 0.01   | 0.03     | 3,965   |
    | **Macro Avg** | 0.59 | 0.51 | 0.49 | 47,526 |
    | **Weighted Avg** | 0.86 | 0.91 | 0.88 | 47,526 |
    """)
    st.markdown("""
    - Classe 0 (Non) :
        Excellente performance globale avec un F1-Score de 0.96.
    - Classe 1 (Oui) :
        Pr√©cision de 26% et rappel de 1%, refl√©tant une faible capacit√© √† d√©tecter les cas positifs.
    - Macro Avg : Le d√©s√©quilibre des performances entre les deux classes est notable.
    - Weighted Avg : Pond√©r√© par le d√©s√©quilibre des classes, il masque les lacunes sur la classe minoritaire.
    """)

    # Scores de performance
    st.subheader("Scores de Performance")
    st.markdown("""
    **Accuracy :** 91%, trompeuse en raison de la domination de la classe majoritaire (92% de "Non").  
    **ROC-AUC :** 0.73, indique une capacit√© mod√©r√©e √† s√©parer les classes, d√©passant l√©g√®rement le seuil de hasard (0.5).
    """)
    
    # Impact du Nombre de Voisins (k)
    st.subheader("Impact du Nombre de Voisins (k)")
    st.markdown("""
    | k      | Accuracy | 
    |--------|-----------|
    | 1      | 0.86      | 
    | 2-6    | 0.91      |    
    | 7-14   | 0.91-0.92 |   
    | 15-20  | 0.92      |           
    
    L'accuracy reste stable autour de 91-92 %, soulignant que le d√©s√©quilibre des classes est un probl√®me inh√©rent.
    """)

    # Recommandations pour am√©lioration
    st.subheader("Am√©liorations Recommand√©es")
    st.markdown("""
    1. **Gestion du d√©s√©quilibre des classes :**
        - Sur-√©chantillonnage : Techniques pour augmenter artificiellement les donn√©es de la classe minoritaire.
        - Sous-√©chantillonnage : R√©duire les √©chantillons de la classe majoritaire.
        - Pond√©ration des Classes : Ajuster les poids pour accorder plus d'importance √† la classe minoritaire.
    2. **Explorer d'autres mod√®les :**
        - Mod√®les robustes au d√©s√©quilibre comme Random Forest, Gradient Boosting ou SVM.
    3. **M√©triques adapt√©es :**
        - Se concentrer sur le F1-Score, le Rappel, et le ROC-AUC pour mieux √©valuer les performances sur la classe minoritaire.
    """)
    
    # Conclusion
    st.header("Conclusion KNN")
    st.markdown("""
    Le mod√®le KNN affiche une accuracy √©lev√©e (91 %), mais √©choue √† d√©tecter efficacement la classe minoritaire.  
    Pour am√©liorer la d√©tection des cas critiques (classe "Oui"), il est essentiel de combiner :  
        - R√©√©quilibrage des donn√©es  
        - Optimisation des m√©triques pertinentes  
        - Exploration de mod√®les alternatifs  
    Ces ajustements am√©lioreront significativement la capacit√© du mod√®le √† traiter les cas rares mais critiques, comme dans les contextes de sant√© ou de d√©tection d'anomalies.
    """)

    # Section 2 : Clustering K-Means
    st.header("Clustering avec K-Means")

    # M√©thode du coude
    st.subheader("M√©thode du Coude")
    st.image("data/images/elbow_kmeans.png", caption="M√©thode du coude")
    st.markdown("""
    La m√©thode du coude montre une diminution rapide de l'inertie jusqu'√† **k=10**, sugg√©rant que 10 clusters pourraient √™tre optimaux.  
    Pour cette analyse, nous avons utilis√© k=2 pour explorer une s√©paration binaire simple.
    """)

    # R√©sultats du clustering
    st.subheader("R√©sultats du Clustering avec k=2")
    st.image("data/images/k_means.png", caption="Visualisation des clusters (PCA)")
    st.markdown("""
    **Matrice de Dispersion des Clusters (R√©duction PCA) :**  
        - Le clustering a √©t√© visualis√© √† l‚Äôaide de la r√©duction de dimensions PCA sur 2 composantes principales.  
        - Les clusters g√©n√©r√©s sont bien distincts dans l‚Äôespace PCA, mais ils ne correspondent pas directement aux classes d√©finies par HadSkinCancer.  
    """)
    
    # Dispersion des Cancer de la Peau dans le Dataset 
    st.subheader("Dispersion des Cancer de la Peau dans le Dataset ")
    st.image("data/images/dispersion.png", caption="Dispersion dans le Dataset")
    st.markdown("""
    **Lors de la visualisation des clusters en fonction de la cible HadSkinCancer :**  
    - Les individus sont r√©partis diff√©remment par le clustering K-Means et la cible r√©elle (HadSkinCancer).
        
    **Observation :**  
        - Les clusters K-Means ne parviennent pas √† capturer la distinction entre les individus ayant ou non un cancer de la peau.  
        - Cela indique que le mod√®le utilise des patterns diff√©rents ou des caract√©ristiques non li√©es √† HadSkinCancer.  
    """)
    
    # R√©sum√© des R√©sultats
    st.subheader("R√©sum√© des R√©sultats")
    st.markdown("""
    1. **Nombre Optimal de Clusters : 10 (m√©thode du coude)**

    2. **Clustering avec k=2 :**
        - Les clusters sont distincts mais ne refl√®tent pas la pr√©sence ou l'absence de cancer de la peau.
        - Cela pourrait √™tre d√ª √† un bruit dans les donn√©es ou √† des caract√©ristiques non discriminantes.

    3. **Pertinence des Caract√©ristiques :**
        - Les variables fournies semblent insuffisantes pour capturer la relation avec HadSkinCancer.
        - Le clustering r√©v√®le potentiellement d'autres structures dans les donn√©es, mais celles-ci ne correspondent pas √† l'objectif d√©fini.
    """)

    # Recommandations pour am√©lioration
    st.subheader("Am√©liorations Recommand√©es")
    st.markdown("""
    1. **Explorer d'autres mod√®les de clustering :**
        - DBSCAN pour d√©tecter des clusters de formes vari√©es.
        - GMM pour capturer des relations probabilistes.
    2. **S√©lection de caract√©ristiques :**
        - Identifier et int√©grer des caract√©ristiques plus corr√©l√©es √† la cible HadSkinCancer.
        - R√©duire le bruit dans les donn√©es par un nettoyage plus rigoureux.
    3. **Ajustement du Nombre de Clusters :**
        - Tester avec k=10 (nombre sugg√©r√© par la m√©thode du coude) pour une segmentation plus fine et voir si elle r√©v√®le des groupes plus significatifs.
    4. **Ajout de M√©triques d'√âvaluation :**
        - Calculer le silhouette score pour √©valuer la coh√©rence des clusters.
        - Utiliser des m√©triques supervis√©es pour mesurer la pertinence des clusters par rapport √† HadSkinCancer.
    """)
    
    # Conclusion
    st.header("Conclusion K-Means")
    st.markdown("""
    Le clustering K-Means a permis de r√©v√©ler des structures dans les donn√©es, mais ces structures ne refl√®tent pas la pr√©sence ou l'absence de cancer de la peau.
    Pour am√©liorer la pertinence du clustering dans ce contexte, il est essentiel :
    - d'Int√©grer des caract√©ristiques plus significatives,
    - d'Explorer des algorithmes alternatifs,
    - d'Ajuster le nombre de clusters.  
    
    Ces am√©liorations permettront d‚Äôobtenir une segmentation plus adapt√©e, particuli√®rement utile dans des applications critiques comme la d√©tection de maladies.
    """)

    # Section 3 : Mod√®le de R√©gression Logistique
    st.header("Mod√®le de R√©gression Logistique")

    # R√©sultats du mod√®le
    st.subheader("R√©sultats du Mod√®le de R√©gression Logistique")
    st.image("data/images/results_reglog.png", caption="R√©sultats de la r√©gression logistique")

    # Matrice de confusion
    st.subheader("Matrice de Confusion")
    st.markdown("""
    |                | Pr√©dit : Non | Pr√©dit : Oui |
    |----------------|--------------|--------------|
    | **R√©el : Non** | 43,561 (TN)  | 0 (FP)       |
    | **R√©el : Oui** | 3,965 (FN)   | 0 (TP)       |
    """)
    st.markdown("""
    **Observations :**  
        - Classe 0 (Non) : Le mod√®le est tr√®s performant pour d√©tecter les cas "Non", avec toutes les pr√©dictions "Non" correctement class√©es (43,561).  
        - Classe 1 (Oui) : Aucune pr√©diction correcte pour la classe "Oui", avec toutes les instances "Oui" class√©es comme "Non" (0 TP).  
    Le mod√®le souffre d'un biais important vers la classe majoritaire et ne d√©tecte pas du tout les cas "Oui".  
    """)
    
    # Rapport de classification
    st.subheader("Rapport de Classification")
    st.markdown("""
    | Classe | Pr√©cision | Rappel | F1-Score | Support |
    |--------|-----------|--------|----------|---------|
    | 0.0    | 0.92      | 1.00   | 0.96     | 43,561  |
    | 1.0    | 0.00      | 0.00   | 0.00     | 3,965   |
    | **Macro Avg**    | 0.46 | 0.50 | 0.48 | 47,526 |
    | **Weighted Avg** | 0.84 | 0.92 | 0.88 | 47,526 |
    """)
    st.markdown("""
    **Observations :**  
        - Classe 0 (Non) : Excellente performance pour cette classe avec un F1-Score de 0.96.  
        - Classe 1 (Oui) : Le mod√®le √©choue compl√®tement √† d√©tecter les cas "Oui", avec un F1-Score de 0.0.  
        - Macro Avg : La moyenne non pond√©r√©e indique de faibles performances globales, avec un F1-Score de 0.48.  
        - Weighted Avg : Le F1-Score √©lev√© de 0.88 est d√ª √† la pr√©dominance de la classe 0, masquant ainsi la mauvaise performance pour la classe 1.
    """)
    
    # Scores de performance
    st.subheader("Scores de Performance")
    st.markdown("""
    **Accuracy :** 92 %, le mod√®le est principalement performant pour la classe majoritaire, mais cette m√©trique est trompeuse en raison du d√©s√©quilibre des classes.
    """)

    # Importance des caract√©ristiques
    st.subheader("Importance des Caract√©ristiques")
    st.image("data/images/features_importance.png", caption="Importance des caract√©ristiques")
    st.markdown("""
    Pour mieux comprendre le fonctionnement du mod√®le, l'importance des caract√©ristiques a √©t√© calcul√©e en fonction des coefficients du mod√®le. 
    Les caract√©ristiques les plus influentes sont :
    - **√Çge :** La variable la plus importante pour pr√©dire les r√©sultats.
    - **Ethnie :** Joue un r√¥le significatif dans les pr√©dictions.
    - **Facteurs secondaires :**
        - Consommation d'alcool
        - Tabagisme
        - Statut VIH (positif/n√©gatif)
    Ces r√©sultats soulignent l'importance de variables d√©mographiques (√¢ge, ethnie) et comportementales dans la pr√©diction, m√™me si la performance globale est limit√©e par le d√©s√©quilibre des classes.
    """)
    
    # Impact du D√©s√©quilibre des Classes
    st.subheader("Impact du D√©s√©quilibre des Classes")
    st.markdown("""
    Le mod√®le de r√©gression logistique affiche une accuracy √©lev√©e de 92 %, mais cette performance est totalement biais√©e par la classe majoritaire (0.0).  
    Le mod√®le n'a pas r√©ussi √† identifier un seul cas de la classe minoritaire (1.0), ce qui montre son incapacit√© √† g√©rer un d√©s√©quilibre marqu√© entre les classes.
    """)
    
    # Recommandations pour am√©lioration
    st.subheader("Am√©liorations Recommand√©es")
    st.markdown("""
    1. **Gestion du D√©s√©quilibre des Classes :**
        - Sur-√©chantillonnage : Augmenter artificiellement les donn√©es de la classe minoritaire (par exemple avec SMOTE).
        - Sous-√©chantillonnage : R√©duire les donn√©es de la classe majoritaire pour √©quilibrer les proportions.
        - Pond√©ration des Classes : Ajuster les poids des classes dans le mod√®le pour donner plus d'importance √† la classe minoritaire.
    2. **Exploration d'Autres Algorithmes :** 
        - Tester des mod√®les plus robustes face au d√©s√©quilibre des classes, tels que Random Forest, Gradient Boosting, ou SVM.
    3. **Utilisation de M√©triques Adapt√©es :**
        - Se concentrer sur des m√©triques comme le F1-Score, le Rappel et **l'AUC-ROC pour √©valuer les performances, surtout sur la classe minoritaire.
    """)
    
    # Conclusion
    st.header("Conclusion R√©gression Logistique")
    st.markdown("""
    Bien que le mod√®le de r√©gression logistique atteigne une accuracy √©lev√©e de 92 %, il est compl√®tement inefficace pour d√©tecter la classe minoritaire (1.0). 
    Ce mod√®le est fortement biais√© par le d√©s√©quilibre des classes, et il est essentiel de :
    - Appliquer des techniques pour traiter ce d√©s√©quilibre (r√©√©chantillonnage, pond√©ration des classes),
    - Choisir des m√©triques adapt√©es √† la classe minoritaire,
    - Explorer des mod√®les plus robustes aux d√©s√©quilibres comme Random Forest ou Gradient Boosting.
    Cela permettra d‚Äôam√©liorer les performances du mod√®le, en particulier pour des t√¢ches critiques comme la d√©tection de maladies ou la classification d‚Äôanomalies.
    """)

    # Conclusion globale
    st.header("Conclusion Globale")
    st.markdown("""
    Les mod√®les KNN, K-Means et r√©gression logistique montrent des limites dans la gestion des d√©s√©quilibres de classes.
    **Ces analyses mettent en √©vidence des pistes claires d'am√©lioration :**
    1. R√©√©quilibrage des donn√©es.
    2. Exploration de mod√®les plus robustes.
    3. Utilisation de m√©triques adapt√©es (F1-Score, ROC-AUC).
    Ces actions permettront d'am√©liorer les performances pour des t√¢ches critiques comme la d√©tection de maladies.
    """)

# Page pour faire une pr√©diction
elif page == "Faire une Pr√©diction par Image":
    st.title("üîç Faire une Pr√©diction par Image")

    # V√©rifier s'il y a des mod√®les disponibles
    if not models_available:
        st.error("‚ö†Ô∏è Aucun mod√®le disponible. Veuillez ajouter des mod√®les dans le dossier 'saved_models'.")
        st.stop()

    # √âtape 1 : S√©lection du mod√®le
    st.markdown("## üìå √âtape 1 : S√©lectionner un mod√®le")
    st.info("S√©lectionnez le mod√®le que vous souhaitez utiliser pour l'analyse des l√©sions cutan√©es.")
    selected_model = st.selectbox(
        "Mod√®les disponibles :", 
        models_available,
        help="Choisissez un mod√®le pr√©-entra√Æn√© pour analyser l'image.",
    )

    model_path = os.path.join(model_dir, selected_model)
    with st.spinner(f"Chargement du mod√®le {selected_model}..."):
        model, model_type = load_selected_model(model_path)
    st.success(f"Mod√®le charg√© : {selected_model} (Type : {model_type})")

    # √âtape 2 : T√©l√©chargement de l'image
    st.markdown("## üìå √âtape 2 : T√©l√©charger une image")
    st.info("Veuillez t√©l√©charger une image de la l√©sion cutan√©e √† analyser. L'image doit √™tre au format **JPEG** ou **PNG**.")
    uploaded_file = st.file_uploader(
        "Choisissez une image de l√©sion cutan√©e :", 
        type=["jpg", "jpeg", "png"],
        help="T√©l√©chargez une image de la peau au format JPG, JPEG ou PNG pour effectuer une pr√©diction.",
    )

    # Fonction de pr√©diction
    def predict_image(file, model, model_type):
        if model_type == "tensorflow":
            # Pr√©parer l'image pour le mod√®le TensorFlow
            img = Image.open(file).resize((224, 224))
            img_array = np.array(img) / 255.0  # Normalisation de l'image
            img_array = np.expand_dims(img_array, axis=0)  # Ajouter une dimension de batch
            prediction = model.predict(img_array)
            return "Malignant" if prediction[0][0] > 0.5 else "Benign"
        elif model_type == "mlp":
            # Pr√©parer l'image pour le mod√®le MLP (scikit-learn)
            img = Image.open(file).resize((224, 224))  # Redimensionner pour MLP
            img_array = np.array(img).flatten().reshape(1, -1)  # Aplatir pour MLP
            prediction = model.predict(img_array)
            return "Malignant" if prediction[0] == 1 else "Benign"
        elif model_type == "pytorch":
            # Pr√©parer l'image pour le mod√®le PyTorch
            img = Image.open(file).resize((224, 224))
            img_array = np.array(img).transpose((2, 0, 1)) / 255.0  # Convertir √† un format CxHxW
            img_tensor = torch.Tensor(img_array).unsqueeze(0)  # Ajouter une dimension de batch
            with torch.no_grad():
                prediction = model(img_tensor)
            return "Malignant" if prediction.item() > 0.5 else "Benign"

    if uploaded_file:
        # Afficher l'image t√©l√©charg√©e
        st.markdown("### üñºÔ∏è Image t√©l√©charg√©e")
        image = Image.open(uploaded_file)
        st.image(image, caption="Image t√©l√©charg√©e √† analyser")

        # √âtape 3 : R√©sultat de la pr√©diction
        st.markdown("## üìå √âtape 3 : R√©sultat de la pr√©diction")
        with st.spinner("üß™ Analyse en cours..."):
            # Faire la pr√©diction
            prediction = predict_image(uploaded_file, model, model_type)

        # Afficher le r√©sultat de la pr√©diction
        if prediction == "Benign":
            st.success("‚úÖ R√©sultat : La l√©sion semble **B√âNIGNE**.")
            st.markdown("### Recommandation :")
            st.write("Cela semble √™tre une l√©sion b√©nigne. Toutefois, si vous avez des pr√©occupations, veuillez consulter un professionnel de sant√©.")
        else:
            st.error("‚ö†Ô∏è R√©sultat : La l√©sion pourrait √™tre **MALIGNE**.")
            st.markdown("### Recommandation :")
            st.write("Veuillez **consulter un professionnel de sant√©** pour un diagnostic plus approfondi.")

elif page == "Faire une Pr√©diction par Profil":
    # Interface utilisateur
    st.title("ü§ñ Pr√©diction personnalis√©e par profil")
    st.markdown("""
    Cette page permet d'effectuer une pr√©diction bas√©e sur des informations personnelles. Le mod√®le utilis√© pour cette pr√©diction est un **Perceptron Multicouche (MLP)**, avec une architecture optimis√©e et entra√Æn√©e sp√©cifiquement pour d√©tecter les risques de cancer de la peau.

    ## Configuration du Mod√®le üîß
    - **Type** : Perceptron Multicouche (MLP)
    - **Architecture** :
    - Premi√®re couche : **50 neurones**
    - Deuxi√®me couche : **30 neurones**
    - **500 √©poques maximum**
    - Fonction d'activation : **ReLU** (Rectified Linear Unit) 

    ### Objectif üéØ
    Le mod√®le pr√©dit la probabilit√© actuelle de risque de cancer de la peau.

    ---

    ## Formulaire Utilisateur üìù
    Pour effectuer la pr√©diction, l'utilisateur doit fournir les informations suivantes :
    1. **√âtat de r√©sidence** : Choisissez parmi une liste d'√âtats am√©ricains (ex. Alabama, Alaska, etc.)
    2. **Sexe** : Homme ou Femme 
    3. **Cat√©gorie d'√¢ge** : Une des plages d'√¢ge pr√©d√©finies (ex. 18-24 ans, 25-29 ans, etc.)
    4. **IMC (Indice de Masse Corporelle)** : Un curseur permet de d√©finir une valeur entre **10.0** et **70.0**
    5. **Statut de fumeur** : Indiquez si vous √™tes fumeur (Oui/Non)
    6. **Utilisation de cigarettes √©lectroniques** : Oui ou Non
    7. **Ethnicit√©** : S√©lectionnez une cat√©gorie (ex. White only, Non-Hispanic)

    ---

    ## R√©sultats de la Pr√©diction üìä
    Apr√®s soumission des informations :
    1. **Probabilit√©s pr√©dictives** :
    - **Classe Positive (cancer probable)** : Affichage de la probabilit√© en pourcentage.
    - **Classe N√©gative (cancer improbable)** : Affichage de la probabilit√© en pourcentage.
    2. **Repr√©sentation graphique** :
    - Un graphique en barres montre la distribution des probabilit√©s entre les deux classes.

    ---

    ### Exemple de R√©sultat
    - **Classe Positive** : 65.34% (indique un risque √©lev√© de cancer de la peau).
    - **Classe N√©gative** : 34.66% (indique un risque faible).

    Un graphique est g√©n√©r√© pour permettre une analyse visuelle rapide de la probabilit√©.

    ---

    > **Note** : Les pr√©dictions fournies par cet outil sont uniquement √† titre informatif. Pour tout doute ou risque de sant√©, il est fortement recommand√© de consulter un professionnel de sant√©.
    """)

    # Cr√©ation du formulaire utilisateur
    state = st.selectbox("√âtat", ["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "District of Columbia", "Florida", "Georgia", "Guam", "Hawaii", "Idaho", "Illinois"])
    sex = st.selectbox("Sexe", ["Male", "Female"])
    age_category = st.selectbox("Cat√©gorie d'√¢ge", ["Age 18 to 24", "Age 25 to 29", "Age 30 to 34", "Age 35 to 39", "Age 40 to 44", "Age 45 to 49", "Age 50 to 54", "Age 55 to 59", "Age 60 to 64", "Age 65 to 69", "Age 70 to 74", "Age 75 to 79", "Age 80 to older"])
    bmi = st.slider("IMC (Indice de Masse Corporelle)", 10.0, 70.0, 25.0, step=0.1)
    smoker_status = st.selectbox("Statut de fumeur", ["Never smoked", "Former smoker", "Current smoker - now smokes every day"])
    e_cigarette_usage = st.selectbox("Utilisation de cigarettes √©lectroniques", [
        "Never used e-cigarettes in my entire life",
        "Not at all (right now)",
        "Use them some days"
    ])
    race_ethnicity = st.selectbox("Ethnicit√©", ["Black only, Non-Hispanic", "Hispanic", "Multiracial, Non-Hispanic", "Other race only, Non-Hispanic", "White only, Non-Hispanic"])
    alchool_drinkers = st.selectbox("Alcool", ["Yes", "No"])
    hiv_testing = st.selectbox("Test VIH", ["Yes", "No"])

    # process data to int
    hiv_testing = 1 if hiv_testing == "Yes" else 0
    alchool_drinkers = 1 if alchool_drinkers == "Yes" else 0

    # Lorsque l'utilisateur clique sur "Pr√©dire"
    if st.button("Faire une pr√©diction"):
        # Fonction pour faire une pr√©diction
        def predict_profil(model, features):
            return model.predict_proba([features])[0]

        model, model_type = load_selected_model("./saved_models/mlp_model.pkl")
        if not model:
            st.error("‚ö†Ô∏è Aucun mod√®le disponible. Veuillez ajouter des mod√®les dans le dossier 'saved_models' en lan√ßant le fichier train_neuron.py.")
            st.stop()

        # Convertir les entr√©es en format utilisable pour le mod√®le
        user_features = [
            state, sex, age_category, bmi, smoker_status, e_cigarette_usage, race_ethnicity, alchool_drinkers, hiv_testing
        ]
        
        encoder = joblib.load("./saved_models/encoders.pkl")
        if not encoder:
            st.error("‚ö†Ô∏è Aucun encoder disponible. Veuillez ajouter des encoders dans le dossier 'saved_models' en lan√ßant le fichier train_neuron.py.")
            st.stop()

        user_features_encoded = []
        important_columns = ['State', 'Sex', 'AgeCategory', 'BMI', 'SmokerStatus', 'ECigaretteUsage', 'RaceEthnicityCategory', 'AlcoholDrinkers', 'HIVTesting']
        for i, col in enumerate(important_columns):
            if col in encoder:  # V√©rifie si la colonne a un encodeur
                feature_value = user_features[i]
                if feature_value not in encoder[col].classes_:
                    st.error(f"‚ö†Ô∏è Valeur inconnue '{feature_value}' d√©tect√©e pour la colonne '{col}'. Veuillez v√©rifier vos donn√©es.")
                    st.stop()
                transformed = encoder[col].transform([feature_value])
                user_features_encoded.append(transformed[0])
            else:
                # Ajouter directement les valeurs num√©riques ou non encod√©es
                user_features_encoded.append(user_features[i])

        print(user_features_encoded)
        user_features_encoded = np.array(user_features_encoded) 

        # Pr√©diction
        prediction = predict_profil(model, user_features_encoded)
        
        # Afficher les r√©sultats
        st.markdown("## üìä R√©sultats de la Pr√©diction")
        st.write(f"Classe Positive (cancer probable) : {prediction[1] * 100:.2f}%")
        st.write(f"Classe N√©gative (cancer improbable) : {prediction[0] * 100:.2f}%")

        # Visualisation des probabilit√©s
        fig, ax = plt.subplots()
        ax.bar(["Classe N√©gative", "Classe Positive"], prediction, color=["green", "red"])
        ax.set_ylabel("Probabilit√©")
        ax.set_title("Probabilit√©s Pr√©dictives")
        st.pyplot(fig)
        

# Page pour le benchmark des mod√®les
elif page == "Benchmark des Mod√®les":
    st.title("üìä Benchmark des Mod√®les")

    st.markdown("""
    Cette page compare les performances des diff√©rents mod√®les utilis√©s pour la d√©tection du cancer de la peau.
    
    ## Comparaison des R√©sultats des Mod√®les
    Les tableaux et graphiques ci-dessous montrent les performances (accuracy, AUC, temps d'entra√Ænement, etc.) de chaque mod√®le.
    """)

    # Ajouter une visualisation de type tableau pour comparer les performances des mod√®les
    benchmark_results = {
        "Mod√®le": ["VGG", "ResNet", "EfficientNet", "MLP (Moyenne)", "Sequential"],
        "Accuracy": [0.85, 0.87, 0.86, 0.78, 0.79],
        "Training Time (seconds)": [300, 350, 280, 100, 150],
        "AUC": [0.87, 0.88, 0.85, 0.76, 0.80]
    }

    benchmark_df = pd.DataFrame(benchmark_results)
    st.dataframe(benchmark_df)

    # Graphique pour comparer les accuracy des mod√®les
    st.markdown("### Comparaison de l'Accuracy des Mod√®les")
    st.bar_chart(benchmark_df.set_index("Mod√®le")["Accuracy"])

    # Graphique pour comparer le temps d'entra√Ænement
    st.markdown("### Temps d'Entra√Ænement des Mod√®les")
    st.bar_chart(benchmark_df.set_index("Mod√®le")["Training Time (seconds)"])

    # Afficher des barres de progression pour les performances
    st.markdown("### Visualisation des Performances des Mod√®les")
    for index, row in benchmark_df.iterrows():
        st.markdown(f"**{row['Mod√®le']}**")
        percentage = int(row['Accuracy'] * 100)
        st.progress(percentage)
        st.write(f"Accuracy: {percentage}%")


    curve_dir = './training_curves'
    model_names = ["VGG", "ResNet", "EfficientNet", "Sequential"]

    for model_name in model_names:
        accuracy_curve_path = os.path.join(curve_dir, f"{model_name}_accuracy_curve.png")
        loss_curve_path = os.path.join(curve_dir, f"{model_name}_loss_curve.png")

        if os.path.exists(accuracy_curve_path) and os.path.exists(loss_curve_path):
            st.markdown(f"#### Courbes d'Apprentissage pour le Mod√®le {model_name}")
            st.image(accuracy_curve_path, caption=f"Courbe d'Accuracy - {model_name}")
            st.image(loss_curve_path, caption=f"Courbe de Loss - {model_name}")

    # Courbes d'apprentissage pour chaque mod√®le
    st.markdown("### Courbes d'Apprentissage des Mod√®les")
    st.markdown("""
        Les courbes d'apprentissage ci-dessous montrent l'√©volution des m√©triques de **Loss** et **Accuracy** pendant l'entra√Ænement de chaque mod√®le. Ces courbes permettent de visualiser le comportement des mod√®les au fur et √† mesure de l'apprentissage, tant sur l'ensemble d'entra√Ænement que sur l'ensemble de validation.

        - **Courbe de Loss** : Repr√©sente la mesure de l'erreur de pr√©diction du mod√®le au fil des epochs. Une baisse r√©guli√®re de la loss indique que le mod√®le apprend correctement.
        - **Courbe d'Accuracy** : Montre l'√©volution de la pr√©cision du mod√®le. Plus la courbe monte, plus le mod√®le devient performant.

        Les courbes permettent de d√©terminer si le mod√®le est en train de **sous-apprendre** (les deux courbes sont faibles) ou de **sur-apprendre** (forte diff√©rence entre les courbes d'entra√Ænement et de validation).
    """)

    st.markdown("#### Mod√®les MLP")
    mlp_image = Image.open("data/images/mlp_results.png")
    st.image(mlp_image, caption="Courbes d'Apprentissage - Mod√®les MLP")

    st.markdown("""
        Ce graphique permet de repr√©senter l'efficacit√© des mod√®les MLP en fonction du nombre de neurones dans les couches cach√©es et en soulignant l'accuracy, le temps d'entra√Ænement et le temps d'√©valuation.
        Gr√¢ce √† ce graphique, nous pouvons voir qu'un grand nombre de neurones dans les couches cach√©es n'entra√Æne pas n√©cessairement une meilleure accuracy et prends plus de temps d'entra√Ænement. Cependant, un certains nombre de neuronnes est requis pour le bon fonctionnement du mod√®le.
        Comme on peut le voir, le mod√®le contenant uniquement 1 neuronne dans la couche cach√©e est le moins performant avec une accuracy en dessous de 50%.      
        
        En analysant les performances des mod√®les, nous pouvons d√©terminer le mod√®le le plus efficace qui est celui √† deux couches cach√©es avec 64 et 32 neurones respectivement.
        Ce mod√®le a le temps d'entrainement le plus court et une accuracy similaire aux autres mod√®les.      
    """)

    # Conclusion sur le benchmark
    st.markdown("## Conclusion")
    st.markdown("""
    Apr√®s avoir compar√© les performances des diff√©rents mod√®les, il semble que **ResNet** soit le mod√®le le plus performant, avec une **accuracy** de 0.88 et un **AUC** de 0.88. Toutefois, cela a un co√ªt en termes de temps d'entra√Ænement, qui est relativement √©lev√©.

    Pour des applications o√π la pr√©cision est cruciale, **ResNet** semble √™tre le meilleur choix. Si le temps d'entra√Ænement est une contrainte importante, alors **EfficientNet** offre un bon compromis entre performance et temps d'entra√Ænement.
                
    Le pire choix reste le mod√®le MLP √† 1 neurone.
    """)
